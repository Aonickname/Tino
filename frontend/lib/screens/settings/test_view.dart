import 'dart:async';
import 'dart:typed_data';
import 'package:flutter/material.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:web_socket_channel/web_socket_channel.dart';
import 'package:flutter_dotenv/flutter_dotenv.dart';


class AzureSTTPage extends StatefulWidget {
  const AzureSTTPage({super.key});

  @override
  State<AzureSTTPage> createState() => _AzureSTTPageState();
}

class _AzureSTTPageState extends State<AzureSTTPage> {
  final recorder = FlutterSoundRecorder();
  final channel = WebSocketChannel.connect(
    Uri.parse(dotenv.env['WEBSOCKET_URL']!),
  );

  final StreamController<Uint8List> _audioController = StreamController<Uint8List>();
  bool isRecording = false;
  List<String> transcript = [];
  final ScrollController _scrollController = ScrollController();

  @override
  void initState() {
    super.initState();

    // WebSocketì—ì„œ í…ìŠ¤íŠ¸ ìˆ˜ì‹ 
    channel.stream.listen((data) {
      setState(() {
        transcript.add(data.toString());
      });

      // ìë™ ìŠ¤í¬ë¡¤ ì•„ë˜ë¡œ ì´ë™
      WidgetsBinding.instance.addPostFrameCallback((_) {
        if (_scrollController.hasClients) {
          _scrollController.animateTo(
            _scrollController.position.maxScrollExtent,
            duration: const Duration(milliseconds: 300),
            curve: Curves.easeOut,
          );
        }
      });
    });

    // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ WebSocketìœ¼ë¡œ ì „ë‹¬
    _audioController.stream.listen((buffer) {
      channel.sink.add(buffer); // Uint8List ì „ì†¡
    });
  }

  Future<void> startRecording() async {
    await Permission.microphone.request();
    if (!(await Permission.microphone.isGranted)) {
      print("ğŸ¤ ë§ˆì´í¬ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.");
      return;
    }

    await recorder.openRecorder();
    await recorder.startRecorder(
      toStream: _audioController.sink,
      codec: Codec.pcm16,
      sampleRate: 16000,
      numChannels: 1,
    );

    setState(() => isRecording = true);
  }

  Future<void> stopRecording() async {
    await recorder.stopRecorder();
    await recorder.closeRecorder();
    await _audioController.close();
    setState(() => isRecording = false);
  }

  @override
  void dispose() {
    recorder.closeRecorder();
    channel.sink.close();
    _scrollController.dispose();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(title: const Text("Azure ì‹¤ì‹œê°„ STT")),
      body: Column(
        children: [
          const SizedBox(height: 10),
          ElevatedButton(
            onPressed: isRecording ? stopRecording : startRecording,
            child: Text(isRecording ? "â¹ ì¤‘ì§€" : "ğŸ™ ì‹œì‘"),
          ),
          const SizedBox(height: 10),
          Expanded(
            child: ListView.builder(
              controller: _scrollController,
              itemCount: transcript.length,
              itemBuilder: (context, index) {
                return Align(
                  alignment: Alignment.centerLeft,
                  child: Container(
                    margin: const EdgeInsets.symmetric(vertical: 4, horizontal: 8),
                    padding: const EdgeInsets.all(12),
                    decoration: BoxDecoration(
                      color: Colors.blue[100],
                      borderRadius: const BorderRadius.only(
                        topLeft: Radius.circular(16),
                        topRight: Radius.circular(16),
                        bottomRight: Radius.circular(16),
                      ),
                    ),
                    child: Text(
                      transcript[index],
                      style: const TextStyle(fontSize: 16),
                    ),
                  ),
                );
              },
            ),
          ),
        ],
      ),
    );
  }
}
