from typing import List
from fastapi import WebSocket, WebSocketDisconnect, APIRouter
import os
import asyncio
import azure.cognitiveservices.speech as speechsdk
from dotenv import load_dotenv
import json

load_dotenv()
router = APIRouter()

class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []
    
    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
    
    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)
    
    async def broadcast(self, message: str):
        for connection in list(self.active_connections):
            try:
                await connection.send_text(message)
            except:
                self.disconnect(connection)

manager = ConnectionManager()

# âœ¨ ì „ì—­ ë³€ìˆ˜ë¡œ ì„ ì–¸í•˜ì—¬ ëª¨ë“  ì—°ê²°ì—ì„œ ê³µìœ  âœ¨
recordings = []

# --- (STT ì›¹ì†Œì¼“ ì½”ë“œ) ---
SPEECH_KEY = os.getenv("SPEECH_KEY")
REGION = os.getenv("REGION")

def run_coroutine_in_thread(coro):
    try:
        loop = asyncio.get_running_loop()
        loop.create_task(coro)
    except RuntimeError:
        asyncio.run(coro)

@router.websocket("/ws/stt/{directory}")
async def stt_websocket(websocket: WebSocket, directory: str):
    await websocket.accept()
    print("âœ… STT í´ë¼ì´ì–¸íŠ¸ê°€ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.")

    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=REGION)
    speech_config.speech_recognition_language = "ko-KR"

    stream_format = speechsdk.audio.AudioStreamFormat(samples_per_second=16000, bits_per_sample=16, channels=1)
    push_stream = speechsdk.audio.PushAudioInputStream(stream_format)

    audio_config = speechsdk.AudioConfig(stream=push_stream)
    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)

    async def send_recognized_text(evt):
        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech and evt.result.text:
            recognized_text = evt.result.text
            print(f"âœ… ìµœì¢… ì¸ì‹: {recognized_text}")
            await websocket.send_text(recognized_text)
            
            # ì „ì—­ ë¦¬ìŠ¤íŠ¸ì— í…ìŠ¤íŠ¸ ì¶”ê°€
            recordings.append({"text": recognized_text})

    speech_recognizer.recognized.connect(lambda evt: run_coroutine_in_thread(send_recognized_text(evt)))
    
    speech_recognizer.session_started.connect(lambda evt: print(f"--- ì„¸ì…˜ ì‹œì‘ë¨ ---"))
    speech_recognizer.session_stopped.connect(lambda evt: print(f"--- ì„¸ì…˜ ì¤‘ë‹¨ë¨ ---"))

    speech_recognizer.start_continuous_recognition_async()

    # íŒŒì¼ì´ ì €ì¥ë  ê¸°ë³¸ ë£¨íŠ¸ í´ë”
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    upload_root = os.path.join(base_dir, "uploaded_files")

    # ìµœì¢… íŒŒì¼ ì €ì¥ ê²½ë¡œë¥¼ ë§Œë“­ë‹ˆë‹¤.
    save_path = os.path.join(upload_root, directory, "result.json")

    try:
        while True:
            audio_data = await websocket.receive_bytes()
            push_stream.write(audio_data)

    except WebSocketDisconnect:
        print("ğŸ”Œ STT í´ë¼ì´ì–¸íŠ¸ ì—°ê²°ì´ ëŠì–´ì¡ŒìŠµë‹ˆë‹¤.")
    finally:
        speech_recognizer.stop_continuous_recognition_async()
        push_stream.close()
        print("ğŸ—‘ï¸ STT ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.")
        
        # ìµœì¢… JSON íŒŒì¼ë¡œ ì €ì¥
        with open(save_path, "w", encoding="utf-8") as f:
            json.dump({"segments": recordings}, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ìµœì¢… JSON íŒŒì¼ì´ '{save_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")